

#### DISCO（论文：DISCO: Distilling Counterfactuals with Large Language Models）
引入了一种基于 LLM 的全自动反事实知识蒸馏方法。它通过工程化的提示使用 LLM 生成短语扰动，然后通过特定于任务的教师模型过滤这些扰动，以提取高质量的反事实数据。

来源：洛桑联邦理工学院自然语言处理实验室、艾伦人工智能研究所
GitHub：https://github.com/eric11eca/disco


#### Lion （论文：Lion: Adversarial Distillation of Closed-Source Large Language Model）
利用LLM的适应性强的特点来提高学生模型的表现。它提示LLM识别并生成“hard”指令，然后利用这些指令来增强学生模型的能力。这种方法利用了LLM用途广泛的特性来指导学生模型的学习，以解决复杂的指令和任务。

来源：香港科技大学
GitHub：https://github.com/YJiangcm/Lion
学生模型：LLaMA-7B
教师模型：ChatGPT(GPT-3.5)